%    Sidebar about panic:
% 	panic is the kernel's last resort: the impossible has happened and the
% 	kernel does not know how to proceed.  In xv6, panic does ...
\chapter{Traps and device drivers}
\label{CH:TRAP}

There are three situations in which some event causes the CPU to set
aside its ordinary sequential execution of instructions and forces a
transfer of control to special code that handles the event. One
situation is a system call, when a user program 
executes the {\tt ecall} instruction to ask the kernel to do 
something for it. Another situation is an \indextext{exception}:
an instruction (user or kernel) does something illegal, such as divide
by zero or use an invalid virtual address. The third situation is a
device \indextext{interrupt}, when a device signals that it needs
attention, for example when the disk hardware finishes a read or write
request.

This book uses \indextext{trap} as a generic term for these
situations. Typically whatever code was executing at the time of the
trap will later need to resume, and shouldn't need to be aware that
anything special happened. That is, we often want traps to be
transparent; this is particularly important for interrupts, which the
interrupted code typically doesn't expect. Thus the usual sequence is that
a trap forces a transfer of control into the kernel; the kernel saves
registers and other state so that execution can be resumed; the kernel
executes appropriate handler code (e.g., a system call implementation
or device driver); the kernel restores the saved state and returns
from the trap; and the original code resumes where it left off.

The xv6 kernel handles all traps. This is natural for system calls; it
makes sense for interrupts since isolation demands that user processes
not directly use devices, and because only the kernel has the state
needed for device handling; and it makes sense for exceptions since
xv6 responds to all exceptions from user space by killing the
offending program.

Xv6 trap handling proceeds in four stages: hardware actions taken by
the RISC-V CPU, an assembly ``vector'' that prepares the way for
kernel C code, a C trap handler that decides what to do with the trap,
and the system call or device-driver service routine. While
commonality among the three trap types suggests that a kernel could
handle all traps with a single code path, it turns out to be
convenient to have separate assembly vectors and C trap handlers for
three distinct cases: traps from kernel space, traps from user space,
and timer interrupts.

This chapter ends with a discussion of device drivers. Device handling
is a different topic than traps, but is included here because the
kernel's interaction with device hardware is often driven by
interrupts.

\section{RISC-V trap machinery}

RISC-V supports a number of control registers that the kernel writes to
tell the CPU how to handle interrupts, and that the kernel can read
to find out about an interrupt that has occured. The RISC-V documents
contain the full story~\cite{riscv:priv}. {\tt riscv.h}
\lineref{kernel/riscv.h:1} contains definitions that xv6 uses. Here's
an outline of the most important registers:

\begin{itemize}

\item {\bf stvec}: The kernel writes the address of its trap handler
  here; the RISC-V jumps here to handle a trap.

\item {\bf sepc}: When a trap occurs, RISC-V saves the program counter
  here (since the {\tt pc} is then replaced with {\tt stvec}). The
  {\tt sret} (return from trap) instruction copies {\tt sepc} to the
  {\tt pc}. The kernel can write to {\tt sepc} to control where {\tt
    sret} goes.

\item {\bf scause}: The RISC-V puts a number here that describes
the reason for the trap.

\item {\bf sscratch}: The kernel places a value here that comes in
  handy at the very start of a trap handler.

\item {\bf sstatus}: The SIE bit controls whether device interrupts
  are enabled. If the kernel clears SIE, the RISC-V will defer
  device interrupts until the kernel sets SIE. The SPP bit
  indicates whether a trap came from user mode or supervisor
  mode, and controls to what mode {\tt sret} returns.

\end{itemize}

The above relate to interrupts handled in supervisor mode, and they
cannot be read or written in user mode. There is an equivalent set of
control registers for interrupts handled in machine mode; xv6 uses
them only for the special case of timer interrupts.

When it needs to force a trap, the RISC-V hardware does the
following for all trap types (other than timer interrupts):

\begin{enumerate}

\item If the trap is a device interrupt, and the {\tt sstatus} SIE bit
  is clear, don't do any of the following.

\item Disable interrupts by clearing SIE.

\item Copy the {\tt pc} to {\tt sepc}.

\item Save the current mode (user or supervisor) in the SPP bit in {\tt sstatus}.

\item Set {\tt scause} to reflect the interrupt's cause.

\item Set the mode to supervisor.

\item Copy {\tt stvec} to the {\tt pc}.

\item Start executing at the new {\tt pc}.

\end{enumerate}

It is important that the CPU performs all these steps as
a single operation.
Consider if one of these steps were omitted: for example, the CPU
didn't switch program counters. Then, a trap could switch to
supervisor mode while still running user instructions. Those user
instructions could break the user/kernel isolation, for example by
modifying the {\tt satp} register to point to a page table that
allowed accessing all of physical memory. It is thus important that
the kernel specify the trap entry point, and not the user program.

Note that the CPU doesn't switch to the kernel page table, doesn't
switch to a stack in the kernel, and doesn't save any registers other
than the {\tt pc}. The kernel must perform these tasks if necessary.
One reason that the CPU does minimal work during a trap is to provide
flexibility to software; for example, in some situations no page table
switch is needed, which may increase performance.

\section{Traps from kernel space}

When the xv6 kernel is executing on a CPU, two types of traps can
occur: exceptions and device interrupts. The previous section outlined
the CPU's response to such traps.

When the kernel is executing, it points {\tt stvec}
to the assembly code at {\tt kernelvec}
\lineref{kernel/kernelvec.S:/^kernelvec/}.
Since xv6 is already in the kernel, {\tt kernelvec} can rely
on {\tt satp} being set to the kernel page table, and on the
stack pointer referring to a valid kernel stack.
{\tt kernelvec} saves all registers so that we can
eventually resume the interrupted code without disturbing it.

{\tt kernelvec} saves the registers on the stack of the interrupted
kernel thread, which makes sense because the register values belong to
that thread. This is particularly important if the trap causes a
switch to a different thread -- in that case the trap will actually
return on the stack of the new thread, leaving the interrupted
thread's saved registers safely on its stack.

{\tt kernelvec} jumps to {\tt kerneltrap}
\lineref{kernel/trap.c:/^kerneltrap/} after saving registers.
{\tt kerneltrap} is prepared for two types of traps:
device interrrupts and exceptions. It calls
{\tt devintr}
\lineref{kernel/trap.c:/^devintr/}
to check for and handle the former.
If the trap isn't a device interrupt, it is an exception,
and that is always a fatal error if it occurs in the kernel.

If {\tt kerneltrap} was called due to a timer interrupt, and a
process's kernel thread is running (rather than a scheduler thread),
{\tt kerneltrap} calls {\tt yield} to give other threads a chance to
run. At some point one of those threads will yield, and let our thread
and its {\tt kerneltrap} resume again.
Chapter~\ref{CH:SCHED} explains what happens in {\tt yield}.

When {\tt kerneltrap}'s work is done, it needs to return to whatever
code was interrupted by the trap. Because a {\tt yield} may have
disturbed the saved {\tt sepc} and the saved previous mode in {\tt sstatus},
{\tt kerneltrap} saves them when it starts. It now restores those
control registers and returns to {\tt kernelvec}
\lineref{kernel/kernelvec.S:/call.kerneltrap$/}.
{\tt kernelvec} pops the saved registers from the stack and
executes {\tt sret}, which copies {\tt sepc} to {\tt pc}
and resumes the interrupted kernel code.

It's worth thinking through how the trap return happens if
{\tt kerneltrap} called {\tt yield} due to a timer interrupt.

Xv6 sets a CPU's {\tt stvec} to {\tt kernelvec} when that CPU
enters the kernel from user space; you can see this in {\tt usertrap}
\lineref{kernel/trap.c:/stvec.*kernelvec/}.
There's a window of time when the kernel is executing
but {\tt stvec} has the wrong value, and it's crucial that device
interrupts be disabled during that window.
Luckily the RISC-V always disables interrupts when it starts
to take a trap, and xv6 doesn't enable them again until
after it sets {\tt stvec}.

\section{Traps from user space}

A trap may occur while executing in user space if the
user program makes a
system call ({\tt ecall} instruction), does something
illegal, or if a device interrupts.
The high-level path of a trap from user space is
{\tt uservec}
\lineref{kernel/trampoline.S:/^uservec/},
then {\tt usertrap}
\lineref{kernel/trap.c:/^usertrap/};
and when returning,
{\tt usertrapret}
\lineref{kernel/trap.c:/^usertrapret/}
and then
{\tt userret}
\lineref{kernel/trampoline.S:/^uservec/}.

Traps from user code are more challenging than from the kernel, since
{\tt satp} points to a user page table that doesn't map the 
kernel, and the stack pointer may contain an invalid or even malicious
value.

Because the RISC-V hardware doesn't switch page tables during a trap,
we need the user page table to include a mapping for the trap vector
instructions that {\tt stvec} points to. Further, the trap vector must switch {\tt
  satp} to point to the kernel page table, and in order to avoid a
crash, the vector instructions must be mapped at the same address in the
kernel page table as in the user page table.

Xv6 satisfies these constraints with a \indextext{trampoline} page
that contains the trap vector code. Xv6 maps the trampoline page at
the same virtual address in the kernel page table and in every user
page table. This virtual address is \indexcode{TRAMPOLINE} (as we saw
in Figure~\ref{fig:as} and in Figure~\ref{fig:xv6_layout}). The
trampoline contents are set in {\tt trampoline.S},
and (when executing user code) {\tt stvec} is set to
{\tt uservec}
\lineref{kernel/trampoline.S:/^uservec/}.

When {\tt uservec} starts, every register contains a value owned by
the interrupting code. But {\tt uservec} needs to be able to modify
some registers in order to set {\tt satp} and generate addresses at
which to save the registers. RISC-V provides a helping hand in the
form of the {\tt sscratch} register. The {\tt csrrw} instruction at
the start of {\tt uservec} swaps the contents of {\tt a0} and {\tt
  sscratch}. Now the user code's {\tt a0} is saved; {\tt uservec} has
one register ({\tt a0}) to play with; and {\tt a0} contains whatever
value the kernel previously placed in {\tt sscratch}.

{\tt uservec}'s next task is to save the user registers. Before
entering user space, the kernel sets {\tt sscratch} to point to a
per-process {\tt trapframe} that (among other things) has space to
save all the user registers
\lineref{kernel/proc.h:/^struct.trapframe/}. Because {\tt satp} still
refers to the user page table, {\tt uservec} needs the trapframe to be
mapped in the user address space. When creating each process, xv6
allocates a page for the process's trapframe, and arranges for it
always to be mapped at user virtual address {\tt TRAPFRAME}, which is
just below {\tt TRAMPOLINE}. The process's {\tt p->tf} points to the
trapframe, though at its physical address where it can be accessed
through the kernel page table.

Thus after swapping {\tt a0} and {\tt sscratch}, {\tt a0}
holds a pointer to the current process's trapframe.
{\tt uservec} now saves all user registers there,
including the user's {\tt a0}, read from {\tt sscratch}.

The {\tt trapframe} contains pointers to the current process's
kernel stack, the current CPU's hartid, the address of {\tt usertrap},
and the address of the kernel page table. {\tt uservec}
retrieves these values, switches {\tt satp} to the kernel page table,
and calls {\tt usertrap}.

The job of {\tt usertrap}, like {\tt kerneltrap} is to determine
the cause of the trap, process it, and return
\lineref{kernel/trap.c:/^usertrap/}.
As mentioned above, it first changes {\tt stvec} to process
traps from kernel mode in {\tt kernelvec}.
It saves the {\tt sepc}, again because there might be a
process switch in {\tt usertrap} that could cause {\tt sepc}
to be overwritten.
If the trap is a system call, {\tt syscall} handles it;
if a device interrupt, {\tt devintr};
otherwise it's an exception, and the kernel kills the
faulting process.
The system call path adds four to the saved user {\tt pc}
because RISC-V, in the case of a system call,
leaves the program pointer pointing to the {\tt ecall} instruction.
On the way out, {\tt usertrap} checks if the process has been
killed or should yield the CPU (if this trap is a timer interrupt).

The first step in returning to user space is the call to {\tt usertrapret}
\lineref{kernel/trap.c:/^usertrapret/}.
This function sets up the RISC-V control registers to prepare for a
future trap from user space. This involves changing {\tt stvec}
to refer to {\tt uservec}, preparing the trapframe fields that
{\tt uservec} relies on, and setting {\tt sepc} to the previously
saved user program counter. At the end, {\tt usertrapret}
calls {\tt userret} on the trampoline page that is mapped in
both user and kernel page tables; the reason is that assembly
code in {\tt userret} will switch page tables.

{\tt usertrapret}'s call to {\tt userret} passes a pointer to the process's user
page table in {\tt a0} and {\tt TRAPFRAME} in {\tt a1}
\lineref{kernel/trampoline.S:/^userret/}.
{\tt userret} switches {\tt satp} to the process's user page table.
Recall that the user page table maps both the trampoline page
and {\tt TRAPFRAME}, but nothing else from the kernel.
Again, the fact that the trampoline page is mapped at the same
virtual address in user and kernel page tables is what allows
{\tt uservec} to keep executing after changing {\tt satp}.
{\tt trapret} copies the trapframe's saved user {\tt a0} to {\tt sscratch}
in preparation for a later swap with with TRAPFRAME.
From this point on, the only data {\tt userret} can use is
the register contents and the content of the trapframe.
Next {\tt userret} restores saved user registers from the trapframe,
does a final swap of {\tt a0} and {\tt sscratch} to restore the
user {\tt a0} and save {\tt TRAPFRAME} for the next trap,
and uses {\tt sret} to return to user space.

\section{Timer interrupts}

Xv6 uses timer interrupts to maintain its clock and to enable it to
switch among compute-bound processes; the {\tt yield} calls in {\tt
  usertrap} and {\tt kerneltrap} cause this switching. Timer
interrupts come from clock hardware attached to each RISC-V CPU. Xv6
programs this clock hardware to interrupt each CPU periodically.

RISC-V requires that timer interrupts be taken in machine mode, not
supervisor mode. RISC-V machine mode executes without paging, and with
a separate set of control registers, so it's not practical to run
ordinary xv6 kernel code in machine mode. As a result, xv6 handles
timer interrupts completely separately from the trap mechanism laid
out above.

%% The xv6 timer interrupt handler asks the RISC-V hardware to
%% generate a ``software interrupt;'' after the timer interrupt finishes,
%% the RISC-V delivers the software interrupt in supervisor mode, using
%% the ordinary trap machinery outlined above.

Code executed in machine mode in {\tt start.c}, before {\tt main},
sets up to receive timer interrupts
\lineref{kernel/start.c:/^timerinit/}.
Part of the job is to program the CLINT hardware (core-local interruptor)
to generate an interrupt after a certain delay.
Another part is to set up a scratch area, analogous to the trapframe,
for the timer interrupt handler to save registers in and find
the address of the CLINT registers.
Finally, {\tt start} sets {\tt mtvec} to {\tt timervec} and
enables timer interrupts.

A timer interrupt can occur at any point when user or kernel code is
executing; there's no way for the kernel to disable timer interrupts
during critical operations. Thus the timer interrupt handler must do
its job in a way guaranteed not to disturb interrupted kernel code.
The basic strategy is for the timer interrupt to ask the RISC-V to
raise a ``software interrupt'' and immediately return. The RISC-V
delivers software interrupts to the kernel with the ordinary trap
mechanism, and allows the kernel to disable them. The code to
handle the software interrupt generated by a timer interrupt can be
seen in {\tt devintr} \lineref{kernel/trap.c:/machine-mode.timer/}.

The machine-mode timer interrupt vector is {\tt timervec} 
\lineref{kernel/kernelvec.S:/^timervec/}.
It saves a few registers in the scratch area prepared by {\tt start},
tells the CLINT when to generate the next timer interrupt,
asks the RISC-V to raise a software interrupt,
restores registers, and returns.
There's no C code involved in a timer interrupt.

\section{Code: Calling system calls}

Chapter~\ref{CH:FIRST} ended with 
\indexcode{initcode.S}
invoking the {\tt exec} system call
\lineref{user/initcode.S:/SYS_exec/}.
Let's look at how the user call
makes its way to the {\tt exec} system call's
implementation in the kernel.

The user code places the arguments for
\indexcode{exec}
in registers {\tt a0} and {\tt a1}, and puts the
system call number in
\texttt{a7}.
System call numbers match the entries in the syscalls array,
a table of function pointers
\lineref{kernel/syscall.c:/syscalls/}.
The \lstinline{ecall} instruction traps into the kernel
and executes {\tt uservec},
{\tt usertrap}, and then {\tt syscall}, as we saw above.

\indexcode{Syscall}
\lineref{kernel/syscall.c:/^syscall/} 
loads the system call number from the trapframe, which
contains the saved
\texttt{a7},
and indexes into the system call table.
For the first system call, 
\texttt{a7}
contains the value 
\indexcode{SYS_exec}
\lineref{kernel/syscall.h:/SYS_exec/},
and
\lstinline{syscall}
will call the 
\lstinline{SYS_exec}'th 
entry of the system call table, which corresponds to calling
\lstinline{sys_exec}.

\lstinline{Syscall}
records the return value of the system call function in
\lstinline{p->tf->a0}.
When the system call returns to user space,
\lstinline{userret}
will load the values from
\indexcode{p->tf}
into the machine registers
and return to user space
using
\lstinline{sret}.
Thus, when 
\lstinline{exec}
returns in user space, it will return in \lstinline{a0} the value
that the system call handler returned
\lineref{kernel/syscall.c:/a0 = syscalls/}.
System calls conventionally return negative numbers to indicate
errors, and zero or positive numbers for success.
If the system call number is invalid,
\lstinline{syscall}
prints an error and returns $-1$.

\section{Code: System call arguments}

Later chapters will examine the implementation of
particular system calls.
This chapter is concerned with the system call mechanism.
There is one bit of mechanism left: finding the system call arguments.

The C calling convention on RISC-V specifies that arguments are
passed in registers.
During a system call, these registers (the saved user registers)
are available in the trapframe, {\tt p->tf}.
The functions
\lstinline{argint},
\lstinline{argaddr},
and
\lstinline{argfd}
retrieve the 
\textit{n} 'th 
system call
argument, as either an integer, pointer, or a file descriptor.
They all call {\tt argraw} to retrieve one of the saved
user registers
\lineref{kernel/syscall.c:/^argraw/}.

Some system calls pass pointers as arguments, and the kernel must use
those pointers to read or write user memory. The {\tt exec} system
call, for example, passes the kernel an array of pointers
referring to string arguments in user space.
These pointers pose
two challenges. First, the user program may be buggy or malicious, and
may pass the kernel an invalid pointer or a pointer intended to trick
the kernel into accessing kernel memory instead of user memory.
Second, the xv6 kernel page table mappings are not the same as the
user page table mappings, so the kernel cannot use ordinary
instructions to load or store from user-supplied addresses.

A number of kernel functions need to perform safe reads from user space;
{\tt fetchstr} is an example \lineref{kernel/syscall.c:/^fetchstr/}.
File system calls such as
{\tt exec} use {\tt fetchstr} to retrieve string arguments from user
space.
\lstinline{fetchstr} calls \lstinline{copyinstr},
which looks up a virtual address in a user page
table, turn it into an address the kernel can use,
and copies a string from the address into the kernel.

\indexcode{copyinstr}
\lineref{kernel/vm.c:/^copyinstr/} copies up to \lstinline{max} bytes to
\lstinline{dst} from virtual address \lstinline{srcva} in the user page
table \lstinline{pagetable}.  It uses {\tt walkaddr}
(which calls {\tt walk}) to walk the page table in software to
determine the physical address \lstinline{pa0} for \lstinline{srcva}.
Since the kernel maps all physical RAM addresses to the same
kernel virtual address,
{\tt copyinstr} can directly copy string bytes from {\tt pa0} to {\tt dst}.
{\tt walkaddr} 
\lineref{kernel/vm.c:/^walkaddr/}
checks that the user-supplied virtual address is part of
the process's user address space, so programs
cannot trick the kernel into reading other memory.
A similar function, {\tt copyout}, copies data from the
kernel to a user-supplied address.

\section{Device drivers}

A
\indextext{driver}
is the code in an operating system that manages a particular device:
it tells the device hardware to perform operations,
configures the device to generate interrupts when done,
handles the resulting interrupts,
and interacts with processes that may be waiting
for I/O from the device.
Driver code can be tricky
because a driver executes concurrently with the device that it manages.  In
addition, the driver must understand the device's hardware interface,
which can be complex and poorly documented.

Devices that need attention from the operating system can usually be
configured to generate interrupts, which are one type of trap.
The kernel trap handling code must be able to recognize when the device
has raised an interrupt and call the driver's interrupt handler;
in xv6, this dispatch happens in {\tt devintr} \lineref{kernel/trap.c:/^devintr/}.

Many device drivers have two main parts: code that runs as part of a
process, and code that runs at interrupt time. The process-level code
is driven by system calls such as {\tt read} and {\tt write} that want
the device to perform I/O. This code may ask the hardware to start an
operation (e.g., ask the disk to read a block); then the code waits for
the operation to complete. Eventually the device completes the
operation and raises an interrupt. The driver's interrupt handler
figures out what operation (if any) has completed, wakes up a waiting
process if appropriate, and perhaps tells the hardware to start work
on any waiting next operation.

\section{Code: The console driver}

The console driver is a simple illustration of driver structure. The
console driver accepts characters typed by a human, via the \indextext{UART}
serial-port hardware attached to the RISC-V. The driver accumulates a
line of input at a time, processing special input characters such as
backspace and control-u. User processes, such as the shell, can use
the {\tt read} system call to fetch lines of input from the console.
When you type input to xv6 in QEMU, your keystrokes are delivered to
xv6 by way of QEMU's simulated UART hardware.

The UART hardware that the driver talks to is a 16550
chip~\cite{ns16550a} emulated by QEMU. On a real computer, a 16550
would manage an RS232 serial link connecting to a terminal or other
computer. When running QEMU, it's connected to your keyboard and
display.

The UART hardware appears to software as a set of memory-mapped
control registers. That is, there are some physical addresses that 
RISC-V hardware connects to the UART device, so that loads and stores
interact with the device hardware rather than RAM.
The memory-mapped address for the UART is 0x10000000, or {\tt UART0}
\lineref{kernel/memlayout.h:/UART0.0x/}.
There are a handful of UART control registers, each the width
of a byte. Their offsets from {\tt UART0} are defined in
\lineref{kernel/uart.c:/define.RHR/}. For example, the
{\tt LSR} register contain bits that indicate whether input
characters are waiting to be read by the software. These
characters (if any) are available for reading from the
{\tt RHR} register. Each time one is read, the UART hardware
deletes it from an internal FIFO of waiting characters, and
clears the ``ready'' bit in {\tt LSR} when the FIFO is empty.

Xv6's {\tt main} calls {\tt consoleinit}
\lineref{kernel/console.c:/^consoleinit/} to initialize the UART
hardware, and to configure the UART hardware to generate input
interrupts \lineref{kernel/uart.c:/^uartinit/}.

The xv6 shell reads from the console by way of a file descriptor
opened by {\tt init.c} \lineref{user/init.c:/open..console/}. Calls to
the {\tt read} system call make their way through the kernel to {\tt
  consoleread} \lineref{kernel/console.c:/^consoleread/}. {\tt
  consoleread} waits for input to arrive (via interrupts) and be
buffered in {\tt cons.buf}, copies the input to user space, and (after
a whole line has arrived) returns to the user process. If the user
hasn't typed a full line yet, any reading processes will wait in the
{\tt sleep} call
\lineref{kernel/console.c:/sleep..cons/}
(Chapter~\ref{CH:SCHED} explains the details of {\tt sleep}).

When the user types a character, the UART hardware asks the RISC-V
to raise an interrupt. The RISC-V and xv6 process the interrupt
as described above, and xv6's trap handling code calls {\tt devintr}
\lineref{kernel/trap.c:/^devintr/}.
{\tt devintr} looks at the RISC-V {\tt scause} register to discover that
the interrupt is from an external device.
Then it asks a hardware unit called the PLIC
\cite{riscv:priv}
to tell it which device interrupted
\lineref{kernel/trap.c:/plic.claim/}.
If it was the UART, {\tt devintr} calls {\tt uartintr}.

{\tt uartintr}
\lineref{kernel/uart.c:/^uartintr/}
reads any waiting input characters from the UART hardware
and hands them to {\tt consoleintr}; it doesn't
wait for characters, since future input will raise a new interrupt.
The job of {\tt consoleintr} is to accumulate input characters in
{\tt cons.buf} 
until a whole line arrives.
{\tt consoleintr} treats backspace and a few other characters
specially.
When a newline arrives, {\tt consoleintr} wakes up a
waiting {\tt consoleread} (if there is one).

Once woken, {\tt consoleread} will observe a full line in {\tt
  cons.buf}, copy it to user space, and return (via the system call
machinery) to user space.

On a multi-core machine, the interrupt may be delivered to any of the
CPUs; the PLIC manages this decision. The interrupt may arrive on the
same CPU that is running the process reading from the console; or it
may arrive on a CPU that is doing something entirely unrelated. Thus
interrupt handlers are not allowed to think about the process or code
that they have interrupted.

\section{Real world}

The need for special trampoline pages could be eliminated if kernel
memory were mapped into every process's user page table. That would
also eliminate the need for a page table switch when trapping from
user space into the kernel. That in turn would allow system call
implementations in the kernel to take advantage of the current
process's user memory being mapped, allowing kernel code to directly
dereference user pointers. Many operating systems use these ideas to
increase efficiency. Xv6 avoids them in order to reduce the chances of
security bugs in the kernel due to inadvertent use of user pointers,
and to reduce some complexity that would be required to ensure that
user and kernel virtual addresses don't overlap.

Xv6 allows device and timer interrupts while executing in the kernel,
as well as when executing user programs. Timer interrupts force a
thread switch (a call to {\tt yield}) from the timer interrupt
handler, even when executing in the kernel. The ability to time-slice
the CPU fairly among kernel threads is useful if kernel threads
sometimes spend a lot of time computing, without returning to user
space. However, the need for kernel code to be mindful that it might
be suspended (due to a timer interrupt) and later resume on a
different CPU is the source of some complexity in xv6. The kernel
could be made somewhat simpler if device and timer interrupts only
occurred while executing user code.

Supporting all the devices on a typical computer in its full glory is
much work, because there are many devices, the devices have many
features, and the protocol between device and driver can be complex
and poorly documented. In many operating systems, the drivers account
for more code than the core kernel.

The UART driver retrieves data a byte at a time by reading the UART
control registers; this pattern is called \indextext{programmed I/O}, since
software is driving the data movement. Programmed I/O is simple, but
too slow to be used at high data rates. Devices that need to move lots
of data at high speed typically use \indextext{direct memory access (DMA)}.
DMA device hardware directly writes incoming data to RAM, and reads
outgoing data from RAM. Modern disk and network devices use DMA. A
driver for a DMA device would prepare data in RAM, and then use a
single write to a control register to tell the device to process the
prepared data.

Interrupts make sense when a device needs attention at unpredictable
times, and not too often. But interrupts have high CPU overhead. Thus
high speed devices, such networks and disk controllers, use tricks
that reduce the need for interrupts. One trick is to raise a single
interrupt for a whole batch of incoming or outgoing requests. Another
trick is for the driver to disable interrupts entirely, and to check
the device periodically to see if it needs attention. This technique
is called \indextext{polling}. Polling makes sense if the device performs
operations very quickly, but it wastes CPU time if the device is mostly
idle. Some drivers dynamically switch between polling and interrupts
depending on the current device load.

The UART driver copies incoming data first to a buffer in the kernel,
and then to user space. This makes sense at low data rates, but such a
double copy can significantly reduce performance for devices that
generate or consume data very quickly. Some operating systems are able
to directly move data between user-space buffers and device hardware,
often with DMA.

\section{Exercises}

\begin{enumerate}

\item \texttt{uartputc} \lineref{kernel/uart.c:/^uartputc/} polls the
  UART device to wait for it to finish with the previous output
  character. Convert it to use interrupts instead.
  
\item Add a driver for an Ethernet card.

\end{enumerate}
